
# Continue restoration config
cn_config:
  current_step: 0
  main_path: ./torch_ao/maxentropy
  previous_step_path: ./torch_ao/maxentropy/step_001

# Active Learning Config
al_config:
  train_name: active_learning
  style: maxentropy # random, ui, maxentropy, maxentropy_dist
  random_state: 123
  override_reset_model: 1

  # root_dir: "AL"
  root_dir: "./torch_ao"
  main_dir: "maxentropy" # dual_al_random
  val_n_sample: 1000
  test_n_sample: 3000
  max_steps: 15

  # active learning parameters
  m: 50 # 200, start 200,100
  n: 20  # 100, step sampling
  outlier: 0.01

# Model Config:
model_config:
  train_name: model

  # RETRAIN
  retrain: 0
  premodel_path: .

  load_only: 1
  main_data_dir: ..
  train_dir_list: 
    - new_all_train_400

  main_model_dir: torch_models
  workers: 8
  size: 400
  batch_size: 2
  batch_multiplier: 30
  reweight_sample: 0
  reweight_sample_factor: 2
  single_mode: 1

  epochs: 60
  loss_type: smoothl1loss
  model_type: single_resnext50
  model_kwargs:
    num_ftrs: 1000
    num_classes: 1
    use_init: kaiming
    limit_two: 1
  qk_patience: 15 #10

  optimizer_type: AdamW
  opt_kwargs:
    lr: 0.0002
    weight_decay: 0.000025

  scheduler_type: CosineAnnealingLR
  scheduler_kwargs:
    T_max: 60
    eta_min: 0.0002



