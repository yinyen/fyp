train_name: new_single_resnext101_400

# RETRAIN
retrain: 0
premodel_path: torch_models/new_small_dual_xception_400_v3a_v13/best_qk_model.pth

# load_only: 0
# main_data_dir: ..
# train_dir_list: 
#   - all_train

load_only: 1
main_data_dir: ..
train_dir_list: 
  - new_all_train_400

main_model_dir: torch_models
workers: 8
size: 400
batch_size: 6
batch_multiplier: 10
reweight_sample: 0
reweight_sample_factor: 2
single_mode: 1

epochs: 60
loss_type: smoothl1loss
model_type: single_resnext101
model_kwargs:
  num_ftrs: 1000
  num_classes: 1
  use_init: kaiming
  limit_two: 1
qk_patience: 20
  # mean: 3.3
  # std: 3.0003
  # mean: 0.003
  # std: 0.0003

optimizer_type: AdamW
opt_kwargs:
  lr: 0.0002
  weight_decay: 0.000025

# optimizer_type: SGD
# opt_kwargs:
#   lr: 0.0001
#   momentum: 0.95
#   weight_decay: 0.000025


# scheduler_type: CosineAnnealingWarmRestarts
# scheduler_kwargs:
#   T_0: 10
#   T_mult: 2
#   eta_min: 0.00001
#   last_epoch: -1

scheduler_type: CosineAnnealingLR
scheduler_kwargs:
  T_max: 60
  # eta_min: 0.000005
  eta_min: 0.00002

# https://www.fast.ai/2018/07/02/adam-weight-decay/#implementing-adamw
# adamw with onecycle
